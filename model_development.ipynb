{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\ericm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ericm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imblearn) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ericm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn->imblearn) (1.23.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\ericm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn->imblearn) (1.9.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ericm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn->imblearn) (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ericm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn->imblearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ericm\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from imbalanced-learn->imblearn) (3.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.2.1\n",
      "[notice] To update, run: C:\\Users\\ericm\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from numpy import std\n",
    "import joblib\n",
    "from joblib import load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "# Take random sample of dataframe to reduce size\n",
    "df = df.sample(n=2000000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['AGE', 'GENDER', 'RACE', 'MARITAL_STATUS', 'EDUCATION',\n",
      "       'EMPLOYMENT_AT_ADMISSION', 'LIVING_ARRANGEMENT_AT_ADMISSION',\n",
      "       'ARRESTS_IN_30_DAYS_PRIOR_TO_ADMISSION', 'SERVICES_AT_ADMISSION',\n",
      "       'REASON_FOR_DISCHARGE', 'PRIMARY_SOURCE_OF_REFERRAL',\n",
      "       'PRIOR_TREATMENT_EPISODES', 'PRIMARY_SUBSTANCE_ABUSE',\n",
      "       'FREQUENCY_OF_USE', 'AGE_AT_FIRST_USE', 'ALCOHOL_OR_DRUG_ABUSE',\n",
      "       'DSM_DIAGNOSIS', 'PSYCHIATRIC_PROBLEM', 'HEALTH_INSURANCE',\n",
      "       'PRIMARY_PAYMENT_METHOD', 'FREQUENCY_OF_SELF_HELP_ATTENDANCE', 'STATE'],\n",
      "      dtype='object')\n",
      "(2000000, 22)\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment completed                                     836794\n",
      "Dropped out of treatment                                499802\n",
      "Transferred to another treatment program or facility    429350\n",
      "Terminated by facility                                  113991\n",
      "Other                                                    84383\n",
      "Incarcerated                                             30904\n",
      "Death                                                     4776\n",
      "Name: REASON_FOR_DISCHARGE, dtype: int64 \n",
      "\n",
      "Ambulatory, non-intensive outpatient                1004351\n",
      "Detox, 24-hour, free-standing residential            298593\n",
      "Ambulatory, intensive outpatient                     269067\n",
      "Rehab/residential, short term (30 days or fewer)     206980\n",
      "Rehab/residential, long term (more than 30 days)     151165\n",
      "Detox, 24-hour, hospital inpatient                    49220\n",
      "Ambulatory, detoxification                            15568\n",
      "Rehab/residential, hospital (non-detox)                5056\n",
      "Name: SERVICES_AT_ADMISSION, dtype: int64 \n",
      "\n",
      "One or more prior treatment episodes    1119440\n",
      "No prior treatment episode               712031\n",
      "Not known                                168529\n",
      "Name: PRIOR_TREATMENT_EPISODES, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['REASON_FOR_DISCHARGE'].value_counts(), '\\n')\n",
    "print(df['SERVICES_AT_ADMISSION'].value_counts(), '\\n')\n",
    "print(df['PRIOR_TREATMENT_EPISODES'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing cases where the patient was transferred to another facility, we cannnot evaluate the effectiveness of the treatment if the patient was transferred to another facility\n",
    "df = df[df['REASON_FOR_DISCHARGE'] != 'Transferred to another treatment program or facility']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1293487\n",
      "1     277163\n",
      "Name: SUCCESSFUL_TREATMENT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create the target variable. If the patient completed treatment and had no prior treatment episodes, they are considered a success. Otherwise, they are considered a failure.\n",
    "df['SUCCESSFUL_TREATMENT'] = df.apply(lambda row: 1 if row['REASON_FOR_DISCHARGE'] == 'Treatment completed' and row['PRIOR_TREATMENT_EPISODES'] == \"No prior treatment episode\" else 0, axis=1)\n",
    "\n",
    "print(df['SUCCESSFUL_TREATMENT'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1256520, 193) (314130, 193) (1256520,) (314130,)\n"
     ]
    }
   ],
   "source": [
    "# Get the initial splits\n",
    "target = df['SUCCESSFUL_TREATMENT']\n",
    "features = df.drop(['REASON_FOR_DISCHARGE', 'PRIOR_TREATMENT_EPISODES', 'SUCCESSFUL_TREATMENT'], axis=1)\n",
    "features_one_hot = pd.get_dummies(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_one_hot, target, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1034928\n",
      "1    1034928\n",
      "Name: SUCCESSFUL_TREATMENT, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Outcomes are unbalanced, so balancing the data in this step via oversampling\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_res, y_train_res = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_train_res.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207054, 193) (207054,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_res.shape, y_train_res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for naive_bayes: 0.5293381720943559\n",
      "f1 score for naive_bayes: 0.505049770859473\n",
      "Precision score for naive_bayes: 0.5990615461066588\n",
      "Recall score for naive_bayes: 0.6630622027018243\n",
      "Standard Deviation of predictions for naive_bayes: 0.48957431251156075 \n",
      "\n",
      "Accuracy score for logistic_regression: 0.7063858911915449\n",
      "f1 score for logistic_regression: 0.6357156619705722\n",
      "Precision score for logistic_regression: 0.6381629152344367\n",
      "Recall score for logistic_regression: 0.7241470781216843\n",
      "Standard Deviation of predictions for logistic_regression: 0.48603250854283236 \n",
      "\n",
      "Accuracy score for random_forest: 0.8226116575939898\n",
      "f1 score for random_forest: 0.678373621008752\n",
      "Precision score for random_forest: 0.6898927366395385\n",
      "Recall score for random_forest: 0.6693832991067857\n",
      "Standard Deviation of predictions for random_forest: 0.36039241201465727 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define and train baseline models for a quick comparison to inform model selection and fine-tuning\n",
    "models_to_train = {\n",
    "    \"naive_bayes\": GaussianNB(),\n",
    "    \"logistic_regression\": LogisticRegression(max_iter=1000),\n",
    "    \"random_forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for model_name, model in models_to_train.items():\n",
    "    model.fit(X_train_res, y_train_res)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"Accuracy score for {model_name}: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"f1 score for {model_name}: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"Precision score for {model_name}: {precision_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"Recall score for {model_name}: {recall_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"Standard Deviation of predictions for {model_name}: {std(y_pred)}\", '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1 fits failed out of a total of 5.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py\", line 1088, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\ensemble\\_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\tree\\_classes.py\", line 458, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 148, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 248, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 763, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 734, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 36, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 58720256 bytes\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_final2.pkl']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the best performing model (Random Forest) using a grid search and 5 fold cross validation\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100], #100, 200, 400, \n",
    "    'max_depth': [12], #5, 15, None\n",
    "    'min_samples_split': [2], #2, 5, 10\n",
    "    'min_samples_leaf': [1] #1, 4, 6\n",
    "}\n",
    "\n",
    "# Define model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Grid\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=3)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(grid_search.best_estimator_, 'model_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\ericm\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.2 when using version 1.1.3. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for random forest: 0.7101995988921784\n",
      "f1 score for random_forest: 0.6386375807513665\n",
      "Precision score for random forest: 0.6397266511451345\n",
      "Recall score for random_forest: 0.7256373106835932\n",
      "Standard Deviation of predictions for random_forest: 0.48490912154020654 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model and evaluate performance on the test set\n",
    "with open('model_final.pkl', 'rb') as file:\n",
    "    model = load(file)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"Accuracy score for random forest: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"f1 score for random_forest: {f1_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"Precision score for random forest: {precision_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"Recall score for random_forest: {recall_score(y_test, y_pred, average='macro')}\")\n",
    "print(f\"Standard Deviation of predictions for random_forest: {std(y_pred)}\", '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 12, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 200, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_columns = ['AGE_12-14','AGE_15-17','AGE_18-20','AGE_21-24','AGE_25-29','AGE_30-34','AGE_35-39','AGE_40-44',\n",
    "               'AGE_45-49','AGE_50-54','AGE_55-64','AGE_65+']\n",
    "\n",
    "gender_columns = ['GENDER_Female','GENDER_Male','GENDER_Not known']\n",
    "\n",
    "race_columns = ['RACE_Alaskan Native','RACE_American Indian','RACE_Asian','RACE_Asian or Pacific Islander',\n",
    "                'RACE_Black or African American','RACE_Native Hawaiian or Other Pacific Islander','RACE_Not known',\n",
    "                'RACE_Other single race','RACE_Two or more races','RACE_White']\n",
    "\n",
    "marriage_columns = ['MARITAL_STATUS_Divorced, widowed','MARITAL_STATUS_Never married','MARITAL_STATUS_Not known',\n",
    "                    'MARITAL_STATUS_Now Married','MARITAL_STATUS_Separated']\n",
    "\n",
    "education_columns = ['EDUCATION_1-3 years of college, university, or vocational school',\n",
    "'EDUCATION_4 years of college, university, BA/BS, some postgraduate study, or more',\n",
    "'EDUCATION_Grade 12 (or GED)',\n",
    "'EDUCATION_Grades 9 to 11',\n",
    "'EDUCATION_Less than one school grade, no schooling, nursery school, or kindergarten to Grade 8',\n",
    "'EDUCATION_Not known']\n",
    "\n",
    "employ_columns = ['EMPLOYMENT_AT_ADMISSION_Full time','EMPLOYMENT_AT_ADMISSION_Not in labor force',\n",
    "                  'EMPLOYMENT_AT_ADMISSION_Not known','EMPLOYMENT_AT_ADMISSION_Part time',\n",
    "                  'EMPLOYMENT_AT_ADMISSION_Unemployed']\n",
    "\n",
    "living_columns = ['LIVING_ARRANGEMENT_AT_ADMISSION_Dependent living','LIVING_ARRANGEMENT_AT_ADMISSION_Homeless',\n",
    "                  'LIVING_ARRANGEMENT_AT_ADMISSION_Independent living','LIVING_ARRANGEMENT_AT_ADMISSION_Not known']\n",
    "\n",
    "arrests_columns = ['ARRESTS_IN_30_DAYS_PRIOR_TO_ADMISSION_None','ARRESTS_IN_30_DAYS_PRIOR_TO_ADMISSION_Not known',\n",
    "                   'ARRESTS_IN_30_DAYS_PRIOR_TO_ADMISSION_Once','ARRESTS_IN_30_DAYS_PRIOR_TO_ADMISSION_Two or more times']\n",
    "\n",
    "referral_columns = ['PRIMARY_SOURCE_OF_REFERRAL_Alcohol/drug use care provider',\n",
    "                    'PRIMARY_SOURCE_OF_REFERRAL_Court/criminal justice referral/DUI/DWI',\n",
    "                    'PRIMARY_SOURCE_OF_REFERRAL_Employer/EAP', \n",
    "                    'PRIMARY_SOURCE_OF_REFERRAL_Individual (includes self-referral)',\n",
    "                    'PRIMARY_SOURCE_OF_REFERRAL_Not known',\n",
    "                    'PRIMARY_SOURCE_OF_REFERRAL_Other community referral',\n",
    "                    'PRIMARY_SOURCE_OF_REFERRAL_Other health care provider',\n",
    "                    'PRIMARY_SOURCE_OF_REFERRAL_School (educational)']\n",
    "\n",
    "sub_columns = ['PRIMARY_SUBSTANCE_ABUSE_Alcohol','PRIMARY_SUBSTANCE_ABUSE_Barbiturates','PRIMARY_SUBSTANCE_ABUSE_Benzodiazepines',\n",
    "               'PRIMARY_SUBSTANCE_ABUSE_Cocaine/crack','PRIMARY_SUBSTANCE_ABUSE_Hallucinogens','PRIMARY_SUBSTANCE_ABUSE_Heroin',\n",
    "               'PRIMARY_SUBSTANCE_ABUSE_Inhalants','PRIMARY_SUBSTANCE_ABUSE_Marijuana/hashish','PRIMARY_SUBSTANCE_ABUSE_Methamphetamine/speed',\n",
    "               'PRIMARY_SUBSTANCE_ABUSE_Non-prescription methadone','PRIMARY_SUBSTANCE_ABUSE_None','PRIMARY_SUBSTANCE_ABUSE_Not known',\n",
    "               'PRIMARY_SUBSTANCE_ABUSE_Other amphetamines','PRIMARY_SUBSTANCE_ABUSE_Other drugs','PRIMARY_SUBSTANCE_ABUSE_Other opiates and synthetics',\n",
    "               'PRIMARY_SUBSTANCE_ABUSE_Other sedatives or hypnotics','PRIMARY_SUBSTANCE_ABUSE_Other stimulants',\n",
    "               'PRIMARY_SUBSTANCE_ABUSE_Other tranquilizers','PRIMARY_SUBSTANCE_ABUSE_Over-the-counter medications',\n",
    "               'PRIMARY_SUBSTANCE_ABUSE_PCP']\n",
    "\n",
    "freq_columns = ['FREQUENCY_OF_USE_Daily use','FREQUENCY_OF_USE_No use in the past month','FREQUENCY_OF_USE_Not known',\n",
    "                'FREQUENCY_OF_USE_Some use']\n",
    "\n",
    "first_use_columns = ['AGE_AT_FIRST_USE_11 years and under',\n",
    "'AGE_AT_FIRST_USE_12-14 years',\n",
    "'AGE_AT_FIRST_USE_15-17 years',\n",
    "'AGE_AT_FIRST_USE_18-20 years',\n",
    "'AGE_AT_FIRST_USE_21-24 years',\n",
    "'AGE_AT_FIRST_USE_25-29 years',\n",
    "'AGE_AT_FIRST_USE_30 years and older',\n",
    "'AGE_AT_FIRST_USE_Not known']\n",
    "\n",
    "alcohol_columns = ['ALCOHOL_OR_DRUG_ABUSE_Alcohol and other drugs',\n",
    "'ALCOHOL_OR_DRUG_ABUSE_Alcohol only',\n",
    "'ALCOHOL_OR_DRUG_ABUSE_None',\n",
    "'ALCOHOL_OR_DRUG_ABUSE_Other drugs only']\n",
    "\n",
    "dsm_columns = ['DSM_DIAGNOSIS_Alcohol abuse',\n",
    "'DSM_DIAGNOSIS_Alcohol dependence',\n",
    "'DSM_DIAGNOSIS_Alcohol intoxication',\n",
    "'DSM_DIAGNOSIS_Alcohol-induced disorder',\n",
    "'DSM_DIAGNOSIS_Anxiety disorders',\n",
    "'DSM_DIAGNOSIS_Attention deficit/disruptive behavior disorders',\n",
    "'DSM_DIAGNOSIS_Bipolar disorders',\n",
    "'DSM_DIAGNOSIS_Cannabis abuse',\n",
    "'DSM_DIAGNOSIS_Cannabis dependence',\n",
    "'DSM_DIAGNOSIS_Cocaine abuse',\n",
    "'DSM_DIAGNOSIS_Cocaine dependence',\n",
    "'DSM_DIAGNOSIS_Depressive disorders',\n",
    "'DSM_DIAGNOSIS_Not known',\n",
    "'DSM_DIAGNOSIS_Opioid abuse',\n",
    "'DSM_DIAGNOSIS_Opioid dependence',\n",
    "'DSM_DIAGNOSIS_Other mental health condition',\n",
    "'DSM_DIAGNOSIS_Other substance abuse',\n",
    "'DSM_DIAGNOSIS_Other substance dependence',\n",
    "'DSM_DIAGNOSIS_Schizophrenia/other psychotic disorders',\n",
    "'DSM_DIAGNOSIS_Substance-induced disorder']\n",
    "\n",
    "psych_columns = ['PSYCHIATRIC_PROBLEM_No','PSYCHIATRIC_PROBLEM_Not known','PSYCHIATRIC_PROBLEM_Yes']\n",
    "\n",
    "insur_columns = ['HEALTH_INSURANCE_Medicaid',\n",
    "'HEALTH_INSURANCE_Medicare, other (e.g. TRICARE, CHAMPUS)',\n",
    "'HEALTH_INSURANCE_None',\n",
    "'HEALTH_INSURANCE_Not known',\n",
    "'HEALTH_INSURANCE_Private insurance, Blue Cross/Blue Shield, HMO']\n",
    "\n",
    "pay_columns = ['PRIMARY_PAYMENT_METHOD_Medicaid',\n",
    "'PRIMARY_PAYMENT_METHOD_Medicare',\n",
    "'PRIMARY_PAYMENT_METHOD_No charge (free, charity, special research, teaching)',\n",
    "'PRIMARY_PAYMENT_METHOD_Not known',\n",
    "'PRIMARY_PAYMENT_METHOD_Other',\n",
    "'PRIMARY_PAYMENT_METHOD_Other government payments',\n",
    "'PRIMARY_PAYMENT_METHOD_Private insurance (Blue Cross/Blue Shield, other health insurance, workers compensation)',\n",
    "'PRIMARY_PAYMENT_METHOD_Self-pay']\n",
    "\n",
    "selfhelp_columns = ['FREQUENCY_OF_SELF_HELP_ATTENDANCE_1-3 times in the past month',\n",
    "'FREQUENCY_OF_SELF_HELP_ATTENDANCE_4-7 times in the past month',\n",
    "'FREQUENCY_OF_SELF_HELP_ATTENDANCE_8-30 times in the past month',\n",
    "'FREQUENCY_OF_SELF_HELP_ATTENDANCE_No attendance',\n",
    "'FREQUENCY_OF_SELF_HELP_ATTENDANCE_Not known',\n",
    "'FREQUENCY_OF_SELF_HELP_ATTENDANCE_Some attendance, frequency is unknown']\n",
    "\n",
    "state_columns = ['STATE_Alabama','STATE_Alaska','STATE_Arizona','STATE_Arkansas','STATE_California','STATE_Colorado',\n",
    "                 'STATE_Connecticut','STATE_Delaware','STATE_District of Columbia','STATE_Florida','STATE_Georgia',\n",
    "                 'STATE_Hawaii','STATE_Idaho','STATE_Illinois','STATE_Indiana','STATE_Iowa','STATE_Kansas','STATE_Kentucky',\n",
    "                 'STATE_Louisiana','STATE_Maine','STATE_Maryland','STATE_Massachusetts','STATE_Michigan','STATE_Minnesota',\n",
    "                 'STATE_Mississippi','STATE_Missouri','STATE_Montana','STATE_Nebraska','STATE_Nevada','STATE_New Hampshire',\n",
    "                 'STATE_New Jersey','STATE_New Mexico','STATE_New York','STATE_North Carolina','STATE_North Dakota','STATE_Ohio',\n",
    "                 'STATE_Oklahoma','STATE_Pennsylvania','STATE_Puerto Rico','STATE_Rhode Island','STATE_South Carolina',\n",
    "                 'STATE_South Dakota','STATE_Tennessee','STATE_Texas','STATE_Utah','STATE_Vermont','STATE_Virginia',\n",
    "                 'STATE_Washington','STATE_Wisconsin','STATE_Wyoming']\n",
    "\n",
    "feature_lists = [age_columns, gender_columns, race_columns, marriage_columns, education_columns, employ_columns,\n",
    "                living_columns, arrests_columns, referral_columns, sub_columns, freq_columns, first_use_columns,\n",
    "                alcohol_columns, dsm_columns, psych_columns, insur_columns, pay_columns, selfhelp_columns, state_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    }
   ],
   "source": [
    "# Loop through each feature group and remove one at a time to see impact on model performance\n",
    "for x in feature_lists:\n",
    "    temp_df = features_one_hot.drop(columns = x)\n",
    "    \n",
    "    X_train_abl, X_test_abl, y_train_abl, y_test_abl = train_test_split(temp_df, target, test_size=0.2, random_state=42)\n",
    "    ros = RandomOverSampler(random_state=42)\n",
    "    X_train_res_abl, y_train_res_abl = ros.fit_resample(X_train_abl, y_train_abl)\n",
    "    \n",
    "    # Define the parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [100], #100, 200, 400, \n",
    "        'max_depth': [12], #5, 15, None\n",
    "        'min_samples_split': [2], #2,10\n",
    "        'min_samples_leaf': [1] #1,4\n",
    "    }\n",
    "\n",
    "    # Define model\n",
    "    rf_abl = RandomForestClassifier()\n",
    "\n",
    "    # Grid\n",
    "    grid_search_abl = GridSearchCV(estimator=rf_abl, param_grid=param_grid, cv=5, n_jobs=-1, verbose=3)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search_abl.fit(X_train_res_abl, y_train_res_abl)\n",
    "\n",
    "    # Best params\n",
    "    model = grid_search_abl.best_estimator_\n",
    "\n",
    "    y_pred_abl = model.predict(X_test_abl)\n",
    "    \n",
    "    print(f\"Accuracy score for random forest removing {x}: {accuracy_score(y_test_abl, y_pred_abl)}\")\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
